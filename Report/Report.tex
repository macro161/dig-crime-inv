\documentclass{VUMIFPSmagistrinis}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{caption}
\usepackage{color}
\usepackage{float}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{subfig}
\usepackage{hyperref}
\usepackage{wrapfig}

\hypersetup{
colorlinks=true,
linkcolor=blue,
filecolor=magenta,      
urlcolor=cyan,
pdftitle={Overleaf Example},
pdfpagemode=FullScreen,
}


\university{Vilniaus universitetas}
\faculty{Matematikos ir informatikos fakultetas}
\department{Informatikos institutas}
\papertype{Digital Crime Investigation project}
\title{User Activeness Patterns, tracking Linux OS event patterns}

\author{Matas Savickis and Markas Mikalauskas}

\supervisor{Agnė Brilingaitė, Doc., Dr.}
\date{Vilnius – \the\year}

\bibliography{bibliografija}

\begin{document}
\pagenumbering{arabic}

\maketitle
\tableofcontents

\sectionnonum{Introduction}
Linux is one of the most popular server-side operating systems, and on a daily basis any user that interacts with Linux as an daily-driven operating system knows, that a lot of sensitive information is saved, edited, and transferred using Linux and its kernel. In case of a cyber security incident, a need for a tool that would solve a particular vulnerability or at least, help track it down, would be beneficial for fixing said vulnerabilities. As an example, one of the possible tools could be an investigator to inspect the patterns of events that happened in Linux, and in regards to tools which would help investigate cyber security incidents, we will discuss about tools that could be used to monitor events inside Linux operating system and methodology to track behavioral patterns in provided event data.

\section{Existing research solutions}
In this section, a brief overview of existing solutions that were analyzed with a potential small script that would be included as a proof-of-concept implementation of a possible solution. 

\subsection{Analysis}
\subsubsection{Viewing system logs}
One of the first possible implementations would be to make use of system logs existing in Linux OS. It is one of the fundamental steps in understanding user and system activities, such as - authentication logs and system messages, offer insights into user logins, logouts, and critical system events, and these logs are invaluable for diagnosing issues and monitoring system health. To check it out how it works OS wide, these would be the simple bash executable for checking out what type of data system logs collect:

\begin{lstlisting}[language=bash]
    # To view authentication logs using the terminal
    cat /var/log/auth.log 

    # To view system messages
    cat /var/log/syslog
\end{lstlisting}

\noindent And if it were selected into a possible PoC (proof-of-concept) this would be an example Python script:
\begin{lstlisting}[language=Python]
import subprocess

log_file = "/var/log/auth.log"
try:
    log_content = subprocess.check_output(['cat', log_file], 
                    universal_newlines=True)
    
    print(log_content)
except FileNotFoundError:
    print(f"Log file {log_file} not found.")
\end{lstlisting}

\subsubsubsection{Using journalctl}
\textbf{journalctl} is a command-line utility for accessing the \textbf{systemd} journal logs in Linux. It provides a structured and comprehensive view of system activities, making it a powerful tool for tracking user behavior and system events. Continuous monitoring with the -f flag allows real-time access to logs. And if it were selected into a possible PoC this would be an example Python script:
\begin{lstlisting}[language=Python]
import subprocess

process = subprocess.Popen(['journalctl', '-f'], 
            stdout=subprocess.PIPE, stderr=subprocess.PIPE)

while True:
    output = process.stdout.readline().decode()
    if output:
        print(output, end='')
\end{lstlisting}

\subsubsection{Audit Framework auditd}
\textbf{auditd} or Linux Audit Daemon is a user-space component of the Linux Auditing System, responsible for collecting and writing audit log file records to the disk. It is, however, not responsible for viewing the logs, which can be done through ausearch or aureport utilities. Problems like remote shell running on the machine or threats arising from malefactors who have access to the machine would be possible to resolve using this tool. This looks like a great candidate for an implementation using our introductory use cases.

If it were selected into a possible PoC this would be an example Python script:
\begin{lstlisting}[language=Python]
import subprocess

try:
    audit_rules = subprocess.check_output(['auditctl', '-l'], 
        universal_newlines=True)
    print(audit_rules)
except FileNotFoundError:
    print("Auditd is not installed or not running.")
\end{lstlisting}

\subsubsection{File System Event Monitoring}
To monitor file system events in real time a Linux tool like \textbf{inotifywait} could be used. It includes tracking file creations, modifications, deletions, and directory changes. This is crucial for data management, ensuring data integrity, and detecting unauthorized file access. Could be one of the possible solutions for the final product depending on the scope of which it could be used and if it were selected into a possible PoC this would be an example Python script:
\begin{lstlisting}[language=Python]
import subprocess

folder_to_watch = '/path/to/watched/folder'

process = subprocess.Popen(['inotifywait', '-m', '-r', 
            folder_to_watch], stdout=subprocess.PIPE, 
            stderr=subprocess.PIPE)

while True:
    output = process.stdout.readline().decode()
    if output:
        print(output, end='')
\end{lstlisting}

\subsubsection{Viewing Kernel Messages}
The kernel is at the heart of the Linux operating system, and its messages provide insights into system operations and health, to view kernel messages \textbf{dmesg} command could be used, which could help diagnose hardware and driver issues, and offer essential information for system administrators. And if it were selected into a possible PoC this would be an example Python script:
\begin{lstlisting}[language=Python]
import subprocess

process = subprocess.Popen(['dmesg'], stdout=subprocess.PIPE, 
            stderr=subprocess.PIPE)

while True:
    output = process.stdout.readline().decode()
    if output:
        print(output, end='')
\end{lstlisting}

\subsubsection{Capturing Keyboard and Mouse Events}
A notoriously known way to get information in a more of discreet way would be to check and capture user's input - keyboard and mouse events. Of course that comes with a drawback of a huge security and privacy flaw - the user is fully exposed to a tool like a keylogger, which could expose very sensitive data. Tools like \textbf{pynput} in Python allow you to record keystrokes and mouse clicks and while this can be useful for monitoring productivity, it should be approached with caution to respect user privacy. If it were selected into a possible PoC this would be an example Python script:
\begin{lstlisting}[language=Python]
from pynput.keyboard import Key, Listener

def on_key_press(key):
    print(f'Key pressed: {key}')

def on_key_release(key):
    if key == Key.esc:
        # Stop listener on pressing ESC key
        return False

with Listener(on_press=on_key_press, on_release=on_key_release) as 
        listener:
    listener.join()
\end{lstlisting}

\subsubsection{Idle Time Monitoring}
Sometimes invaluable data like a how many hours have been spent inactive during business hours would be useful for micro-management, security or power management, one of the ways to utilize and monitor idle time in Linux would be to use a tool like \textbf{xprintidle} to track the idle time based on user's keyboard and mouse interactions with the OS.

If it were selected into a possible PoC this would be an example Python script:
\begin{lstlisting}[language=Python]
import subprocess

try:
    idle_time_ms = int(subprocess.check_output(['xprintidle'])
                        .decode())
    idle_time_sec = idle_time_ms / 1000
    print(f'User is idle for {idle_time_sec} seconds.')
except FileNotFoundError:
    print("xprintidle is not installed.")
\end{lstlisting}

\subsubsection{Process Monitoring}

Process monitoring is essential for tracking the system calls made by running applications, it can be used with tools like \textbf{strace}, as it is instrumental in diagnosing issues and understanding how processes interact with the operating system, easier to check which processes are running in the background for \textit{n} of time. If it were selected into a possible PoC this would be an example Python script:
\begin{lstlisting}[language=Python]
import subprocess

pid_to_trace = '1234'  # Replace with the PID of the process 
                            you want to trace

process = subprocess.Popen(['strace', '-p', pid_to_trace], 
            stdout=subprocess.PIPE, stderr=subprocess.PIPE)

while True:
    output = process.stdout.readline().decode()
    if output:
        print(output, end='')
\end{lstlisting}

\subsubsection{Active Window Detection}
For the use case of counting for how long a singular window or application has been running can be achieved with tools like \textbf{ewmh} in Python. It helps to understand the user's focus and application usage patterns, which can be valuable for optimizing workflows and identifying resource-intensive tasks, or even micro-managing the user on what has he been doing on company time. If it were selected into a possible PoC this would be an example Python script:
\begin{lstlisting}[language=Python]
from ewmh import EWMH

ewmh = EWMH()

# Get the root window
root = ewmh.root

# Get the active window
active_window = ewmh.getActiveWindow()

print(f'Active Window Title: {active_window.get_wm_name()}')
\end{lstlisting}

\subsubsection{Web Proxy Logs (Squid)}
And last, but not least - Squid, a popular web proxy server, generates access logs that record web traffic. These logs are for tracking user internet activity, ensuring security, and monitoring compliance with internet usage policies, Squid's logs offer insights into web access patterns and can help with content filtering and caching strategies. If our tool would be extended to use IoT or any type of network connection this would be a good candidate for review. If it were selected into a possible PoC this would be an example Python script:
\begin{lstlisting}[language=Python]
import subprocess

# Install Squid if it's not already installed
try:
    subprocess.check_output(['apt-get', 'install', 'squid'], 
                stderr=subprocess.STDOUT)
except subprocess.CalledProcessError as e:
    if "E: Unable to locate package" in e.output.decode():
        print("Squid package not found. Please install it manually.")
    else:
        print(e.output.decode())

# Start the Squid service
try:
    subprocess.check_output(['systemctl', 'start', 'squid'], 
        stderr=subprocess.STDOUT)
    print("Squid service started.")
except subprocess.CalledProcessError as e:
    print("Error starting Squid service:")
    print(e.output.decode())

# View Squid access logs
access_log_file = "/var/log/squid/access.log"
try:
    access_log_content = subprocess
                            .check_output(['cat', access_log_file], 
                            universal_newlines=True)
    print(access_log_content)
except FileNotFoundError:
    print(f"Squid access log file {access_log_file} not found.")
\end{lstlisting}

\subsection{Analysis conclusion}
After testing out overlooked methods for our use case, we have selected that \textbf{auditd} together with some use of \textbf{inotifywait} would be the best tools that would help us out for our use case overview in the introduction.

\subsection{auditd tool}
\textbf{auditd} is similar to a black box on an airplane, it allows system administrators to record various system events such as executed commands, system calls, file access information and network statistics. System administrators can use these logs to detect and track anomalous activity to pinpoint how the system was compromised. This follow-up analysis can help respond to incidents and improve security to avoid similar incidents in the future.

For the use cases that are written in the introduction section possible PoC testing solutions could be used, at least in bash command form before transforming them into a unified CLI tool:
\begin{itemize}
    \item \textbf{To detect file activity outside a designated (protected) folder using a combination of auditd and inotifywait with this example:}
\end{itemize}
\begin{lstlisting}[language=bash]
# Set up inotifywait to watch over the protected folder
inotifywait -m -r -e create,modify,attrib /path/to/protected_folder &

# Set up an auditd rule to log inotifywait events
auditctl -a always,exit -F arch=b64 -S inotify_init1 -k file_activity

# Check the audit logs for file activity outside the designated folder
ausearch -k file_activity
\end{lstlisting}

\begin{itemize}
    \item \textbf{To detect file transfers to external drives:}
\end{itemize}
\begin{lstlisting}[language=bash]
# Set up an audit rule to log file write events to removable devices
auditctl -a always,exit -F dir=/media -F perm=w -k file_transfers

# Check the audit logs for file transfers to external drives
ausearch -k file_transfers
\end{lstlisting}

\begin{itemize}
    \item \textbf{To monitor file modifications after selected (business) hours:}
\end{itemize}
\begin{lstlisting}[language=bash]
# Set up an audit rule to log file writes after work hours 
# (e.g., after 17:00)

auditctl -a always,exit -F arch=b64 -S 
    open,creat,truncate,ftruncate -F dir=/path/to/monitored_folder 
    -F key=after_work_hours -F start=17:00 -F end=05:00

# Check the audit logs for file modifications after work hours
ausearch -k after_work_hours
\end{lstlisting}

\section{Technological challenges}
In this section, we will delve into the technological challenges that might come up whilst creating a tool for a cyber security threat investigation.

    \subsection{Investigation environment}
        For the purpose of this paper, we will imagine that we have some protected folders in Linux.
        This folder will contain text data (in \textbf{.csv} format) of clients' personal information.
        Our imaginary company is running a Lithuanian e-shop website and needs to store users' data for a variety of reasons.
        Data is stored in the following format: \textit{name}, \textit{surname}, \textit{e-mail}, \textit{phone number}, \textit{birth date}, \textit{IP address} and \textit{country}.
    \subsection{Behaviour patterns}
        During normal operation, new users can be created and they can delete data text files.
        To start using \textbf{auditd} we first need to decide on what user behavior could be tracked so that anomalies in said behaviors could be noticed and investigated.

        \begin{itemize}
            \item \textbf{Access Patterns} - editing data files at irregular times. This pattern could tell us if data was accessed in an unusual time which could indicate something suspicious. Accessing data outside working hours or in irregular times, or accessing files very frequently could indicate that something malicious is happening.
            \item \textbf{Data manipulation patterns} - user data can be created when a new user is registered or deleted when the user requests to be deleted. 
            During normal operation users rarely ask to be deleted so a change in the ratio and amount of created/deleted users could indicate something malicious.
            \item \textbf{E-mail pattern} - since the company is based in Lithuania it is expected that most users will either use popular e-mail providers(\textbf{Gmail}, \textbf{Outlook}) or a local Lithuanian e-mail providers like \textbf{Inbox.lt}.
            Using strange and rarely used e-mail providers could indicate that something malicious is happening.
        \end{itemize}

    \subsection{Anomaly detection}
        Being able to collect various data from Linux events is not enough.
        We need to detect anomalous behavior. 
        For this purpose, we will use the mathematical probability model \textbf{Markov Chain}.
        Using this model we construct a probability diagram by giving \textbf{Markov Chain's} model a combination of described behavioral patterns attained from Linux events in hopes of seeing statistical anomalies.

    \subsection{Markov Chain's}
        \href{https://en.wikipedia.org/wiki/Markov}{Markov Chain's}
         were previously used to analyze activities from \href{https://www.researchgate.net/publication/4335500_Cyber_Criminal_Activity_Analysis_Models_using_Markov_Chain_for_Digital_Forensics}{digital forensics}, in which the authors state that early recognition of similar patterns can lead to focusing resources, improving clearance rates, and ultimately saving lives in terms of digital forensics. In their paper the authors proposed a forensics methodology using Markov chain's during a given time interval for tracking and predicting the degree of criminal activity as it evolves over time. In the future, some behavioral patterns might change to fit Markov Chain's model.

	
\section{Hypotheses}
\begin{enumerate}
    \item It is possible to detect anomalies in Linux event behavioral patterns using Markov Chain's.
    \item Differentiated user behaviors within the Linux event data can be used to detect anomalies, potentially uncovering unauthorized access or insider threats.
    \item Changes in file or its attributes and temporal access patterns in flagged as protected Linux folders may serve as reliable indicators for detecting data tampering, breaches, or suspicious activities.
\end{enumerate}
	
\section{Design of the tool}
    The tool will be a Python program using the click library. 
    Click library will enable us to access the terminal console to run the Python program as a terminal script.
    Test data on Linux events will be parsed and inputted to the Markov Chain model.
    After that, the following Linux event will be inputted Markov Chain will say what is probability of said event is.
    If the probability is \textit{lower} then some threshold Linux event will be considered an anomaly and \textbf{flagged} in the report.
    

\section{Algorithm}
    \begin{lstlisting}[language=Python]
Algorithm MarkovChainBasedEventPrediction

Data:
    events: a list of events
    threshold: a threshold value for event probability

Methods:

    Train(events):
        Pass the list of events to a Markov Chain model to generate 
        a transition matrix (or equivalent structure).

    GetProbability(event):
        Use the Markov Chain model to find the probability of 
        the passed event based on previous states.
        Return the calculated probability.

    IsEventProbable(event, threshold):
        probability = GetProbability(event)
        
        If probability < threshold:
            Return False, event
        Else:
            Return True, event

Main:
    Train(events)
    
    For each event in events:
        result, event = IsEventProbable(event, threshold)
        
        If not result:
            Print "Event", event, "is not probable."
        Else:
            Print "Event", event, "is probable."

\end{lstlisting}


\section{Visual report/diagnostics}
    The report will be presented as a scatter plot where the \textit{X-axis} is the event index (or id) or date of the event and the \textit{Y-axis} is the probability of an event.
    Low probability events should be spikes that would indicate that some anomalous event happened and could be a possible malicious activity.

		
\pagebreak
\printbibliography[heading=bibintoc] 

\end{document}
